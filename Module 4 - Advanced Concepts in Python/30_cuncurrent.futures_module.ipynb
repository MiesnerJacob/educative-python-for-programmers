{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The concurrent.futures module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concurrent.futures module\n",
    "\n",
    "The concurrent.futures module was added in python 3.2, and essentially serves as a abstraction layer on top of the threading and multiprociessing modules that makes it easier to work with them but less flexible.\n",
    "\n",
    "There are two main classes in this module: ThreadPoolExecutor (for managing threads) and ProcessPoolExecutor (for managing processes). \n",
    "\n",
    "The future is the result of a process or thread before it has finished, you can think of it as a pending result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pool\n",
    "\n",
    "Here we are using the same code as the asnycio chapter () where we download urls, but here we replace it with the concurrent.futures module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "\n",
    "def downloader(url):\n",
    "    \"\"\"\n",
    "    Downloads the specified URL and saves it to disk\n",
    "    \"\"\"\n",
    "    \n",
    "    # use urllib request to download file\n",
    "    req = urllib.request.urlopen(url)\n",
    "    filename = os.path.basename(url)\n",
    "    ext = os.path.splitext(url)[1]\n",
    "    if not ext:\n",
    "        raise RuntimeError('URL does not contain an extension')\n",
    "\n",
    "    with open(filename, 'wb') as file_handle:\n",
    "        while True:\n",
    "            chunk = req.read(1024)\n",
    "            if not chunk:\n",
    "                break\n",
    "            file_handle.write(chunk)\n",
    "    msg = 'Finished downloading {filename}'.format(filename=filename)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading f1040sb.pdf\n",
      "Finished downloading f1040.pdf\n",
      "Finished downloading f1040es.pdf\n",
      "Finished downloading f1040ez.pdf\n",
      "Finished downloading f1040a.pdf\n"
     ]
    }
   ],
   "source": [
    "# Downloading files asyncronously using the ThreadPoolExecutor sub-class\n",
    "\n",
    "def main(urls):\n",
    "    \"\"\"\n",
    "    Create a thread pool and download specified urls\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use ThreadPoolExecutor class as context manager with 5 workers\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Use list comprehension to create futures\n",
    "        futures = [executor.submit(downloader, url) for url in urls]\n",
    "        # print out results as they are completed\n",
    "        for future in as_completed(futures):\n",
    "            print(future.result())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # specify pdf files to download\n",
    "    urls = [\"http://www.irs.gov/pub/irs-pdf/f1040.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040a.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040ez.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040es.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"]\n",
    "    \n",
    "    # run our function to execute async program\n",
    "    main(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading f1040.pdf\n",
      "Finished downloading f1040a.pdf\n",
      "Finished downloading f1040ez.pdf\n",
      "Finished downloading f1040es.pdf\n",
      "Finished downloading f1040sb.pdf\n"
     ]
    }
   ],
   "source": [
    "# Usig the map function instead of list comprehension to clean code up a bit\n",
    "\n",
    "def main(urls):\n",
    "    \"\"\"\n",
    "    Create a thread pool and download specified urls\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        return executor.map(downloader, urls, timeout=60, chunksize=8)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    urls = [\"http://www.irs.gov/pub/irs-pdf/f1040.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040a.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040ez.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040es.pdf\",\n",
    "            \"http://www.irs.gov/pub/irs-pdf/f1040sb.pdf\"]\n",
    "    results = main(urls)\n",
    "    for result in results:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadlocks\n",
    "\n",
    "Deadlocks are a pitfall of concurrent.futures, wehre the result of one future is waiting on the results of another. This creates a problem where the process cannot finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a deadlock\n",
    "# The calling wait_forever as we do below has one future wait on the results of another!\n",
    "# THIS IS CAUSED BY ONLY HAVING 1 THREAD\n",
    "\n",
    "def wait_forever():\n",
    "    \"\"\"\n",
    "    This function will wait forever if there's only one\n",
    "    thread assigned to the pool\n",
    "    \"\"\"\n",
    "    \n",
    "    my_future = executor.submit(zip, [1, 2, 3], [4, 5, 6])\n",
    "    result = my_future.result()\n",
    "    print(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    executor = ThreadPoolExecutor(max_workers=1)\n",
    "    executor.submit(wait_forever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "# Restructuring the code above to have it work\n",
    "# Here we use return and call .result() on our returned value\n",
    "\n",
    "def wait_forever():\n",
    "    \"\"\"\n",
    "    This function will wait forever if there's only one\n",
    "    thread assigned to the pool\n",
    "    \"\"\"\n",
    "    my_future = executor.submit(zip, [1, 2, 3], [4, 5, 6])\n",
    "\n",
    "    return my_future\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    executor = ThreadPoolExecutor(max_workers=3)\n",
    "    fut = executor.submit(wait_forever)\n",
    "\n",
    "    result = fut.result()\n",
    "    print(list(result.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again as a rule of thumb if you have a process that is network or I/O bound and not much commputation being done locally using threads is fine. Although if you have a more computationally expensive task you will want to use a process instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
