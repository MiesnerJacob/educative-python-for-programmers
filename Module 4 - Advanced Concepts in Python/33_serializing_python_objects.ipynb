{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializaing Python Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving In\n",
    "\n",
    "On the surface, the concept of serialization is simple. You have a data structure in memory that you want to save, reuse, or send to someone else. The data is only meant to be used by the same program that created it, never sent over a network, and never read by anything other than the program that created it. The pickle module is ideal for this use case, its a standard python library with the bulk of it written in C.\n",
    "\n",
    "What can pickle store?:\n",
    "* all native python datatypes\n",
    "* combos of native python datatypes\n",
    "* functions, classes, and instances of classes (with caveats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to a Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2009, tm_mon=3, tm_mday=27, tm_hour=22, tm_min=20, tm_sec=42, tm_wday=4, tm_yday=86, tm_isdst=-1)\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary to pickle\n",
    "import time\n",
    "\n",
    "entry = {}\n",
    "entry['title'] = 'Dive into history, 2009 edition'\n",
    "entry['article_link'] = 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition'\n",
    "entry['comments_link'] = None\n",
    "entry['internal_id'] = b'\\xDE\\xD5\\xB4\\xF8'\n",
    "entry['tags'] = ('diveintopython', 'docbook', 'html')\n",
    "entry['published'] = True\n",
    "entry['published_date'] = time.strptime('Fri Mar 27 22:20:42 2009')\n",
    "\n",
    "print(entry['published_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle our dictionary\n",
    "# pickle is python specific format\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('33_serializing_python_objects_demos/entry.pickle', 'wb') as f:\n",
    "    pickle.dump(entry, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from a Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Dive into history, 2009 edition', 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition', 'comments_link': None, 'internal_id': b'\\xde\\xd5\\xb4\\xf8', 'tags': ('diveintopython', 'docbook', 'html'), 'published': True, 'published_date': time.struct_time(tm_year=2009, tm_mon=3, tm_mday=27, tm_hour=22, tm_min=20, tm_sec=42, tm_wday=4, tm_yday=86, tm_isdst=-1)}\n"
     ]
    }
   ],
   "source": [
    "with open('33_serializing_python_objects_demos/entry.pickle', 'rb') as f:\n",
    "    entry = pickle.load(f)\n",
    "    \n",
    "print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling without a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# pickling a bytes object\n",
    "\n",
    "# Load our pickled object\n",
    "with open('33_serializing_python_objects_demos/entry.pickle', 'rb') as f:    \n",
    "     entry = pickle.load(f)  \n",
    "\n",
    "# pickle our loaded object\n",
    "b = pickle.dumps(entry)\n",
    "\n",
    "# type check\n",
    "print(type(b))\n",
    "\n",
    "# re-pickle object and confirm it matches our loaded object\n",
    "repickled_entry = pickle.loads(b)\n",
    "print(repickled_entry==entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bytes and Strings Rear Their Ugly Heads Again\n",
    "\n",
    "Python 3.0 introduced a new pickle protocol with explicit support for bytes objects and byte arrays. It is a binary format. This python 3 version is compatible with the python 2 version, but not visa versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�\u0004�J\u0001\u0000\u0000\u0000\u0000\u0000\u0000}�(�\u0005title��\u001fDive into history, 2009 edition��\f",
      "article_link��Jhttp://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition��\r",
      "comments_link�N�\u000b",
      "internal_id�C\u0004�մ���\u0004tags��\u000ediveintopython��\u0007docbook��\u0004html����\tpublished���\u000epublished_date��\u0004time��\u000b",
      "struct_time���(M�\u0007K\u0003K\u001bK\u0016K\u0014K*K\u0004KVJ����t�}�(�\u0007tm_zone�N�\ttm_gmtoff�Nu��R�u."
     ]
    }
   ],
   "source": [
    "# printing pickle files from cmd can be messy\n",
    "\n",
    "!cat 33_serializing_python_objects_demos/entry.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0: \\x80 PROTO      4\n",
      "    2: \\x95 FRAME      330\n",
      "   11: }    EMPTY_DICT\n",
      "   12: \\x94 MEMOIZE    (as 0)\n",
      "   13: (    MARK\n",
      "   14: \\x8c     SHORT_BINUNICODE 'title'\n",
      "   21: \\x94     MEMOIZE    (as 1)\n",
      "   22: \\x8c     SHORT_BINUNICODE 'Dive into history, 2009 edition'\n",
      "   55: \\x94     MEMOIZE    (as 2)\n",
      "   56: \\x8c     SHORT_BINUNICODE 'article_link'\n",
      "   70: \\x94     MEMOIZE    (as 3)\n",
      "   71: \\x8c     SHORT_BINUNICODE 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition'\n",
      "  147: \\x94     MEMOIZE    (as 4)\n",
      "  148: \\x8c     SHORT_BINUNICODE 'comments_link'\n",
      "  163: \\x94     MEMOIZE    (as 5)\n",
      "  164: N        NONE\n",
      "  165: \\x8c     SHORT_BINUNICODE 'internal_id'\n",
      "  178: \\x94     MEMOIZE    (as 6)\n",
      "  179: C        SHORT_BINBYTES b'\\xde\\xd5\\xb4\\xf8'\n",
      "  185: \\x94     MEMOIZE    (as 7)\n",
      "  186: \\x8c     SHORT_BINUNICODE 'tags'\n",
      "  192: \\x94     MEMOIZE    (as 8)\n",
      "  193: \\x8c     SHORT_BINUNICODE 'diveintopython'\n",
      "  209: \\x94     MEMOIZE    (as 9)\n",
      "  210: \\x8c     SHORT_BINUNICODE 'docbook'\n",
      "  219: \\x94     MEMOIZE    (as 10)\n",
      "  220: \\x8c     SHORT_BINUNICODE 'html'\n",
      "  226: \\x94     MEMOIZE    (as 11)\n",
      "  227: \\x87     TUPLE3\n",
      "  228: \\x94     MEMOIZE    (as 12)\n",
      "  229: \\x8c     SHORT_BINUNICODE 'published'\n",
      "  240: \\x94     MEMOIZE    (as 13)\n",
      "  241: \\x88     NEWTRUE\n",
      "  242: \\x8c     SHORT_BINUNICODE 'published_date'\n",
      "  258: \\x94     MEMOIZE    (as 14)\n",
      "  259: \\x8c     SHORT_BINUNICODE 'time'\n",
      "  265: \\x94     MEMOIZE    (as 15)\n",
      "  266: \\x8c     SHORT_BINUNICODE 'struct_time'\n",
      "  279: \\x94     MEMOIZE    (as 16)\n",
      "  280: \\x93     STACK_GLOBAL\n",
      "  281: \\x94     MEMOIZE    (as 17)\n",
      "  282: (        MARK\n",
      "  283: M            BININT2    2009\n",
      "  286: K            BININT1    3\n",
      "  288: K            BININT1    27\n",
      "  290: K            BININT1    22\n",
      "  292: K            BININT1    20\n",
      "  294: K            BININT1    42\n",
      "  296: K            BININT1    4\n",
      "  298: K            BININT1    86\n",
      "  300: J            BININT     -1\n",
      "  305: t            TUPLE      (MARK at 282)\n",
      "  306: \\x94     MEMOIZE    (as 18)\n",
      "  307: }        EMPTY_DICT\n",
      "  308: \\x94     MEMOIZE    (as 19)\n",
      "  309: (        MARK\n",
      "  310: \\x8c         SHORT_BINUNICODE 'tm_zone'\n",
      "  319: \\x94         MEMOIZE    (as 20)\n",
      "  320: N            NONE\n",
      "  321: \\x8c         SHORT_BINUNICODE 'tm_gmtoff'\n",
      "  332: \\x94         MEMOIZE    (as 21)\n",
      "  333: N            NONE\n",
      "  334: u            SETITEMS   (MARK at 309)\n",
      "  335: \\x86     TUPLE2\n",
      "  336: \\x94     MEMOIZE    (as 22)\n",
      "  337: R        REDUCE\n",
      "  338: \\x94     MEMOIZE    (as 23)\n",
      "  339: u        SETITEMS   (MARK at 13)\n",
      "  340: .    STOP\n",
      "highest protocol among opcodes = 4\n"
     ]
    }
   ],
   "source": [
    "# printing our pickled object with a cleaner format\n",
    "import pickletools\n",
    "\n",
    "with open('33_serializing_python_objects_demos/entry.pickle', 'rb') as f:\n",
    "    pickletools.dis(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing Python Objects to be Read by Other Languages\n",
    "\n",
    "Pickle is python specific so in order to save objects compatible with other programming languages we will need to use something else. JSON is a great candidate! JSON stands for \"JavaScript Object Notation\" and Python 3 comes with a json standard library for working with these objects.\n",
    "\n",
    "JSON is case-sensitive, and ingores whitespaces, allowing you to \"pretty-print\" your json objects without ramification. JSON must also be stored in a Unicode encoding (UTF-32, UTF-16, or the default, utf-8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to a JSON File\n",
    "\n",
    "* You can use the Javascript eval() function in python to \"decode\" json-serialized dfata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create dictionary object\n",
    "basic_entry = {}\n",
    "basic_entry['id'] = 256\n",
    "basic_entry['title'] = 'Dive into history, 2009 edition'\n",
    "basic_entry['tags'] = ('diveintopython', 'docbook', 'html')\n",
    "basic_entry['published'] = True\n",
    "basic_entry['comments_link'] = None\n",
    "\n",
    "# write dictionary to json file\n",
    "with open('33_serializing_python_objects_demos/basic.json', mode='w', encoding='utf-8') as f:\n",
    "    json.dump(basic_entry, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 256, \"title\": \"Dive into history, 2009 edition\", \"tags\": [\"diveintopython\", \"docbook\", \"html\"], \"published\": true, \"comments_link\": null}"
     ]
    }
   ],
   "source": [
    "# printing our json object via cmd\n",
    "! cat 33_serializing_python_objects_demos/basic.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-saving our json as pretty format\n",
    "# This will be more readable, but also a larger file\n",
    "\n",
    "import json\n",
    "with open('33_serializing_python_objects_demos/basic-pretty.json', mode='w', encoding='utf-8') as f:\n",
    "     json.dump(basic_entry, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"id\": 256,\r\n",
      "  \"title\": \"Dive into history, 2009 edition\",\r\n",
      "  \"tags\": [\r\n",
      "    \"diveintopython\",\r\n",
      "    \"docbook\",\r\n",
      "    \"html\"\r\n",
      "  ],\r\n",
      "  \"published\": true,\r\n",
      "  \"comments_link\": null\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "# printing our pretty-print json object via cmd\n",
    "! cat 33_serializing_python_objects_demos/basic-pretty.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping of Python Datatypes to JSON\n",
    "\n",
    "Python maps pretty cleanly to JSON, but there are two important datatypes that are missing from JSON format. Those include:\n",
    "\n",
    "* tuples (mapped to array objects in json, essentially a list object)\n",
    "* bytes (no support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serializing Datatypes Unsupported by JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# func to handle serializing time and byte objects to JSON\n",
    "def to_json(python_object):\n",
    "    if isinstance(python_object, time.struct_time):\n",
    "        return {'__class__': 'time.asctime',\n",
    "                '__value__': time.asctime(python_object)}\n",
    "    if isinstance(python_object, bytes):\n",
    "        return {'__class__': 'bytes',\n",
    "                '__value__': list(python_object)}\n",
    "    raise TypeError(repr(python_object) + ' is not JSON serializable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write unsupported datatypes to JSON file\n",
    "with open('33_serializing_python_objects_demos/entry.json', 'w', encoding='utf-8') as f:\n",
    "     json.dump(entry, f, indent=2, default=to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"title\": \"Dive into history, 2009 edition\",\r\n",
      "  \"article_link\": \"http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition\",\r\n",
      "  \"comments_link\": null,\r\n",
      "  \"internal_id\": {\r\n",
      "    \"__class__\": \"bytes\",\r\n",
      "    \"__value__\": [\r\n",
      "      222,\r\n",
      "      213,\r\n",
      "      180,\r\n",
      "      248\r\n",
      "    ]\r\n",
      "  },\r\n",
      "  \"tags\": [\r\n",
      "    \"diveintopython\",\r\n",
      "    \"docbook\",\r\n",
      "    \"html\"\r\n",
      "  ],\r\n",
      "  \"published\": true,\r\n",
      "  \"published_date\": [\r\n",
      "    2009,\r\n",
      "    3,\r\n",
      "    27,\r\n",
      "    22,\r\n",
      "    20,\r\n",
      "    42,\r\n",
      "    4,\r\n",
      "    86,\r\n",
      "    -1\r\n",
      "  ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat 33_serializing_python_objects_demos/entry.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Dive into history, 2009 edition', 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition', 'comments_link': None, 'internal_id': {'__class__': 'bytes', '__value__': [222, 213, 180, 248]}, 'tags': ['diveintopython', 'docbook', 'html'], 'published': True, 'published_date': [2009, 3, 27, 22, 20, 42, 4, 86, -1]}\n"
     ]
    }
   ],
   "source": [
    "with open('33_serializing_python_objects_demos/entry.json', mode='r', encoding='utf-8') as f:\n",
    "    entry = json.load(f)\n",
    "    \n",
    "print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see it loaded out file, but didnt convert our date and byte fields because they are non-json compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert our non-json compatible fields back into their correct python types\n",
    "def from_json(json_object):\n",
    "    if '__class__' in json_object:\n",
    "        if json_object['__class__'] == 'time.asctime':\n",
    "            return time.strptime(json_object['__value__'])\n",
    "        if json_object['__class__'] == 'bytes':\n",
    "            return bytes(json_object['__value__'])\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Dive into history, 2009 edition', 'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition', 'comments_link': None, 'internal_id': b'\\xde\\xd5\\xb4\\xf8', 'tags': ['diveintopython', 'docbook', 'html'], 'published': True, 'published_date': [2009, 3, 27, 22, 20, 42, 4, 86, -1]}\n"
     ]
    }
   ],
   "source": [
    "# Load JSON file with non-json compatible objects\n",
    "with open('33_serializing_python_objects_demos/entry.json', 'r', encoding='utf-8') as f:\n",
    "     entry = json.load(f, object_hook=from_json)\n",
    "        \n",
    "print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look you will notice our 'tags' field is now a list instead of tuple, for most cases you can ignore the difference, but this is something to keep in mind when working with converting objects to and from python to JSON."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
