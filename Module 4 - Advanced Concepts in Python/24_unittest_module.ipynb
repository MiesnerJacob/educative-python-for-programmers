{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The unittest Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unittest module in Python\n",
    "\n",
    "The unittest module supports test automation, the sharing of setup and shutdown code, aggregating tests into collections and the independence of tests from the reporting framework.\n",
    "\n",
    "Unittest supports the following concepts:\n",
    "* Test Fixture - sets up and takes down tests\n",
    "* Test Case - Your test, this will typically assert that a specific response comes from a certain set of inputs\n",
    "* Test Suite - A collection of test cases\n",
    "* Test Runner - Controls & orchestrates running test, it can use a GUI or simple text interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/miesner.jacob/python-for-programmers-educative/Module 4 - Advanced Concepts in Python/24_unittest_demos\n",
      "test_add_floats (__main__.TestAdd) ... ok\n",
      "test_add_integers (__main__.TestAdd) ... ok\n",
      "test_add_strings (__main__.TestAdd) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Running example unittest file that runs tests on our functions in an accompanying file\n",
    "%cd 24_unittest_demos\n",
    "\n",
    "# Run the tests written for our add function\n",
    "!python arithmetic_unittests.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-Line Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: python -m unittest [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\r\n",
      "                          [-k TESTNAMEPATTERNS]\r\n",
      "                          [tests [tests ...]]\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  tests                a list of any number of test modules, classes and test\r\n",
      "                       methods.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help           show this help message and exit\r\n",
      "  -v, --verbose        Verbose output\r\n",
      "  -q, --quiet          Quiet output\r\n",
      "  --locals             Show local variables in tracebacks\r\n",
      "  -f, --failfast       Stop on first fail or error\r\n",
      "  -c, --catch          Catch Ctrl-C and display results so far\r\n",
      "  -b, --buffer         Buffer stdout and stderr during tests\r\n",
      "  -k TESTNAMEPATTERNS  Only run tests which match the given substring\r\n",
      "\r\n",
      "Examples:\r\n",
      "  python -m unittest test_module               - run tests from test_module\r\n",
      "  python -m unittest module.TestClass          - run tests from module.TestClass\r\n",
      "  python -m unittest module.Class.test_method  - run specified test method\r\n",
      "  python -m unittest path/to/test_file.py      - run tests from test_file.py\r\n",
      "\r\n",
      "usage: python -m unittest discover [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\r\n",
      "                                   [-k TESTNAMEPATTERNS] [-s START]\r\n",
      "                                   [-p PATTERN] [-t TOP]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -v, --verbose         Verbose output\r\n",
      "  -q, --quiet           Quiet output\r\n",
      "  --locals              Show local variables in tracebacks\r\n",
      "  -f, --failfast        Stop on first fail or error\r\n",
      "  -c, --catch           Catch Ctrl-C and display results so far\r\n",
      "  -b, --buffer          Buffer stdout and stderr during tests\r\n",
      "  -k TESTNAMEPATTERNS   Only run tests which match the given substring\r\n",
      "  -s START, --start-directory START\r\n",
      "                        Directory to start discovery ('.' default)\r\n",
      "  -p PATTERN, --pattern PATTERN\r\n",
      "                        Pattern to match tests ('test*.py' default)\r\n",
      "  -t TOP, --top-level-directory TOP\r\n",
      "                        Top level directory of project (defaults to start\r\n",
      "                        directory)\r\n",
      "\r\n",
      "For test discovery all test modules must be importable from the top level\r\n",
      "directory of the project.\r\n"
     ]
    }
   ],
   "source": [
    "# Looking at all options available in the unittest module\n",
    "!python -m unittest -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_add_floats (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "test_add_integers (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "test_add_strings (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.000s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# Running unittest file from commandline with the following two lines of code removed\n",
    "#if __name__ == '__main__':\n",
    "#    unittest.main()\n",
    "\n",
    "!python -m unittest arithmetic_unittests2.py -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_add_integers (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 0.000s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# Running a specific test in our unittest file\n",
    "\n",
    "!python -m unittest arithmetic_unittests2.TestAdd.test_add_integers -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_add_floats (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "test_add_integers (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "test_add_strings (arithmetic_unittests2.TestAdd) ... ok\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 3 tests in 0.000s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# Running test cases from a specific class\n",
    "\n",
    "!python -m unittest arithmetic_unittests2.TestAdd -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a More Complex Test\n",
    "\n",
    "There is a simple_db.py file in our demo folder for this chapter that creates a db that stores some information on musical artists. There are the following functions in that file:\n",
    "* create_database: creates a sqlite db, a table and inserts some values\n",
    "* delete_artist: remove an artist from our db table\n",
    "* update_artist: update artist name in our db table\n",
    "* select_all_albums: get all albums for a particular artist\n",
    "\n",
    "At the end of the file we run each one of the functions one time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a test file with setUp and tearDown functions to create our db and remove it. This is saved under db_tests.py.\n",
    "\n",
    "Finally, we add a test for updating an artist and another for getting albums names of an artist that does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_artist_does_not_exist (test_db.TestMusicDatabase) ... ok\r\n",
      "test_updating_artist (test_db.TestMusicDatabase) ... ok\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 2 tests in 0.014s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "# Running the unittests that were explained above\n",
    "!python -m unittest test_db.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Test Suites\n",
    "\n",
    "As stated above a test suite is just a collection of test cases. I've created arithmetic_unittestsuite.py to combine some of our arithmetic unittests into a suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n",
      "test_add_floats (arithmetic_unittests.TestAdd) ... ok\n",
      "test_add_integers (arithmetic_unittests.TestAdd) ... ok\n",
      "test_add_strings (arithmetic_unittests.TestAdd) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Running our unittest suite\n",
    "!python -m unittest arithmetic_unittests_suite.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Skip Tests\n",
    "\n",
    "The unittest supports skipping tests. Here are some cases where you may want to skip a test:\n",
    "* One of the library versions in your code doesn't support what you want to test\n",
    "* The test is dependent on the operating system it is running under\n",
    "* Other criteria for skipping tests\n",
    "\n",
    "We are modifying our arithmetic_untittests2.py to include decorators on a few of our tests to have them skipped. The decorators we are using are @unittest.skip() (applied to test_add_strings func) and @unittest.skipUnless() (applied to test_adding_on_windows) which allows a condition. The new file will be saved as arithmetic_untittests3.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_add_floats (arithmetic_unittests3.TestAdd) ... ok\r\n",
      "test_add_integers (arithmetic_unittests3.TestAdd) ... ok\r\n",
      "test_add_strings (arithmetic_unittests3.TestAdd) ... skipped 'Skip this test'\r\n",
      "test_adding_on_windows (arithmetic_unittests3.TestAdd) ... skipped 'requires Windows'\r\n",
      "\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 4 tests in 0.000s\r\n",
      "\r\n",
      "OK (skipped=2)\r\n"
     ]
    }
   ],
   "source": [
    "# Running our arithemtic_untittests3.py file which contains skip decorators\n",
    "!python -m unittest arithmetic_unittests3.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an expectedFailure decorator that you can add to a test that you know will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with doctest\n",
    "\n",
    "doctest and unitests can be used together, unittest supports what is called Test Discovery which basically allows unittest to look at a the contents of a directory and determine from the file name which ones might contain tests. It then loads the test by importing them.\n",
    "\n",
    "We will illustrate this here by creating a my_docs.py files that contains a few simple functions with doctests and a test_doctests.py file that will run the doctests in the my_docs.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'integrating_with_doctest'\n",
      "/Users/miesner.jacob/python-for-programmers-educative/Module 4 - Advanced Concepts in Python/24_unittest_demos/integrating_with_doctest\n",
      "add (my_docs)\n",
      "Doctest: my_docs.add ... ok\n",
      "subtract (my_docs)\n",
      "Doctest: my_docs.subtract ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Running Test Discovery via unittest module\n",
    "%cd integrating_with_doctest\n",
    "\n",
    "!python -m unittest discover -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
